{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab731308",
   "metadata": {},
   "source": [
    "#### Remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e358d59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi this is a html tags remove code.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "remove_html_tags('Hi this is a html tags remove code.<div id=\"site\" style=\"display: block; height: 572.034px;\">')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bdb45",
   "metadata": {},
   "source": [
    "#### Remove url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96723723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url is removed. '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "remove_url('url is removed. www.shakhauat.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873440da",
   "metadata": {},
   "source": [
    "#### Remove punctuation\n",
    "It is flexible, I can use which punctuation need to skip or remove. It is simple just remove or add any punctuation symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b211b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fd8644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation is removed Thank you for using this code \n",
      "Punctuation is removed without removing dot. Thank you for using this code. \n",
      "Simple way to remove punctuation Thank you for using this code\n"
     ]
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    for punc in string.punctuation:\n",
    "        text=text.replace(punc,'')\n",
    "    return text\n",
    "\n",
    "print(remove_punc('Punctuation is removed.! Thank you for using this code. :)'))\n",
    "\n",
    "\n",
    "\n",
    "#Example I don't want to remove (.)dot from my text. Here for that, remove (.)dot from all punctuation symbol-\n",
    "punctuation='!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "def remove_punc_flexible(text):\n",
    "    for punc in punctuation:\n",
    "        text=text.replace(punc,'')\n",
    "    return text\n",
    "print(remove_punc_flexible('Punctuation is removed without removing dot.! Thank you for using this code. :)'))\n",
    "\n",
    "\n",
    "\n",
    "#Simple way to remove punctuation\n",
    "text='Simple way to remove punctuation.! Thank you for using this code.:)'\n",
    "print(text.translate(str.maketrans('','',string.punctuation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d17fd",
   "metadata": {},
   "source": [
    "#### Short chat word detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b259b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_word={\n",
    "'AFAIK':'As Far As I Know',\n",
    "'AFK':'Away From Keyboard',\n",
    "'ASAP':'As Soon As Possible',\n",
    "'ATK':'At The Keyboard',\n",
    "'ATM':'At The Moment',\n",
    "'A3':'Anytime, Anywhere, Anyplace',\n",
    "'BAK':'Back At Keyboard',\n",
    "'BBL':'Be Back Later',\n",
    "'BBS':'Be Back Soon',\n",
    "'BFN':'Bye For Now',\n",
    "'B4N':'Bye For Now',\n",
    "'BRB':'Be Right Back',\n",
    "'BRT':'Be Right There',\n",
    "'BTW':'By The Way',\n",
    "'B4':'Before',\n",
    "'B4N':'Bye For Now',\n",
    "'CU':'See You',\n",
    "'CUL8R':'See You Later',\n",
    "'CYA':'See You',\n",
    "'FAQ':'Frequently Asked Questions',\n",
    "'FC':'Fingers Crossed',\n",
    "'FWIW':'For What Its Worth',\n",
    "'FYI':'For Your Information',\n",
    "'GAL':'Get A Life',\n",
    "'GG':'Good Game',\n",
    "'GN':'Good Night',\n",
    "'GMTA':'Great Minds Think Alike',\n",
    "'GR8':'Great!',\n",
    "'G9':'Genius',\n",
    "'IC':'I See',\n",
    "'ICQ':'I Seek you (also a chat program)',\n",
    "'ILU':'I Love You',\n",
    "'IMHO':'In My Honest/Humble Opinion',\n",
    "'IMO':'In My Opinion',\n",
    "'IOW':'In Other Words',\n",
    "'IRL':'In Real Life',\n",
    "'KISS':'Keep It Simple, Stupid',\n",
    "'LDR':'Long Distance Relationship',\n",
    "'LMAO':'Laugh My A.. Off',\n",
    "'LOL':'Laughing Out Loud',\n",
    "'LTNS':'Long Time No See',\n",
    "'L8R':'Later',\n",
    "'MTE':'My Thoughts Exactly',\n",
    "'M8':'Mate',\n",
    "'PITA':'Pain In The A..',\n",
    "'PRT':'Party',\n",
    "'PRW':'Parents Are Watching',\n",
    "'ROFL':'Rolling On The Floor Laughing',\n",
    "'ASL':'Age, Sex, Location',\n",
    "'THX':'Thank You',\n",
    "'TTFN':'Ta-Ta For Now!',\n",
    "'TTYL':'Talk To You Later',\n",
    "'U':'You',\n",
    "'U2':'You Too',\n",
    "'U4E':'Yours For Ever',\n",
    "'WB':'Welcome Back',\n",
    "'WTF':'What The F...',\n",
    "'WTG':'Way To Go!',\n",
    "'WUF':'Where Are You From?',\n",
    "'W8':'Wait...',\n",
    "'MFW':'My face when',\n",
    "'MRW' : 'My reaction when',\n",
    "'IFYP' :'I feel your pain',\n",
    "'LOL' : 'Laughing out loud',\n",
    "'TNTL' :'Trying not to laugh',\n",
    "'JK' : 'Just kidding',\n",
    "'IDC' : 'I don’t care',\n",
    "'ILY' : 'I love you',\n",
    "'IMU': 'I miss you',\n",
    "'ADIH': 'Another day in hell',\n",
    "'IDC' :'I don’t care',\n",
    "'ZZZ' :'Sleeping, bored, tired',\n",
    "'WYWH': 'Wish you were here',\n",
    "'TIME' :'Tears in my eyes',\n",
    "'BAE' : 'Before anyone else',\n",
    "'FIMH' : 'Forever in my heart',\n",
    "'BSAAW' : 'Big smile and a wink',\n",
    "'BWL' : 'Bursting with laughter',\n",
    "'LMAO' : 'Laughing my a** off',\n",
    "'BFF': 'Best friends forever',\n",
    "'CSL' : 'Can’t stop laughing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368ba0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Night my dear...'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ch(text):\n",
    "    nt=[]\n",
    "    for i in text.split():\n",
    "        if i.upper() in chat_word:\n",
    "            nt.append(chat_word[i.upper()])\n",
    "        else:\n",
    "            nt.append(i)\n",
    "    return ' '.join(nt)\n",
    "\n",
    "ch('gn my dear...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af724abb",
   "metadata": {},
   "source": [
    "#### Spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c58574d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a8dd4",
   "metadata": {},
   "source": [
    "Simple but not effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dece19de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I there, great to sea you\n",
      "simple but not effective\n"
     ]
    }
   ],
   "source": [
    "incorrect_text1='Hi there, gret to sea you'\n",
    "text2='simpile but nopt effective'\n",
    "\n",
    "txtob=TextBlob(incorrect_text)\n",
    "print(txtob.correct().string)\n",
    "\n",
    "txtob2=TextBlob(text2)\n",
    "print(txtob2.correct().string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6e55f",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6c5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23313220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' short written message   send  receive using  mobile phone'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    nt=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            nt.append('')\n",
    "        else:\n",
    "            nt.append(word)\n",
    "    return ' '.join(nt)\n",
    "\n",
    "remove_stopwords('a short written message that you send or receive using a mobile phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cdeeb",
   "metadata": {},
   "source": [
    "#### Emoji handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d412bf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed all the emojies \n",
      "Hi you are :smiling_face_with_heart-eyes:\n"
     ]
    }
   ],
   "source": [
    "#Remove emoji\n",
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern= re.compile('['\n",
    "                              u'\\U0001F600-\\U0001F64F'\n",
    "                              u'\\U0001F300-\\U0001F5FF'\n",
    "                              u'\\U0001F680-\\U0001F6FF'\n",
    "                              u'\\U0001F1E0-\\U0001F1FF'\n",
    "                              u'\\U00002702-\\U00002780'\n",
    "                              u'\\U000024C2-\\U0001F251'\n",
    "                              ']+',flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text)\n",
    "\n",
    "print(remove_emoji('removed all the emojies 😀😃'))\n",
    "\n",
    "\n",
    "#Replace emoji with it's meaning\n",
    "#!pip install emoji\n",
    "\n",
    "import emoji\n",
    "print(emoji.demojize('Hi you are 😍'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ac1ba",
   "metadata": {},
   "source": [
    "#### Dividing sentence into word (tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67620097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'sentence', 'will', 'be', 'used', 'in', 'word', 'tokenize', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sentence = 'this sentence will be used in word tokenize!'\n",
    "\n",
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text preprocessing also includes stemming Lemmatization. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
